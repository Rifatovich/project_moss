import cv2
import numpy as np
import torch
import streamlit as st
import tempfile
import os
from PIL import Image
from io import BytesIO
import albumentations as A
import zipfile
import re
import pandas as pd
from urllib.parse import quote

# ‚Äî‚Äî‚Äî –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ‚Äî‚Äî‚Äî
CLASS_LIST = ["—Ñ–æ–Ω", "–º–æ—Ö", "–ø–æ—á–≤–∞"]
RESIZE_DIM = 512
MACHINE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
torch.classes.__path__ = []
MODEL_NET = torch.jit.load('models/best_model_new.pt', map_location=MACHINE)

# ‚Äî‚Äî‚Äî –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ‚Äî‚Äî‚Äî
def build_augmentation():
    return A.Compose([
        A.LongestMaxSize(max_size=RESIZE_DIM),
        A.PadIfNeeded(min_height=RESIZE_DIM, min_width=RESIZE_DIM),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

# ‚Äî‚Äî‚Äî –ò–Ω—Ñ–µ—Ä–µ–Ω—Å ‚Äî‚Äî‚Äî
def run_inference(image):
    h0, w0, _ = image.shape
    transforms = build_augmentation()
    augmented = transforms(image=image)
    processed = augmented['image']

    input_tensor = torch.from_numpy(processed).to(MACHINE).unsqueeze(0).permute(0, 3, 1, 2).float()
    MODEL_NET.eval()
    with torch.no_grad():
        prediction = MODEL_NET(input_tensor)
        softmaxed = torch.softmax(prediction, dim=1)

    softmaxed = softmaxed.squeeze().cpu().detach().numpy()
    predicted_class = np.argmax(softmaxed, axis=0)

    if h0 > w0:
        delta = int(((h0 - w0) / 2) / h0 * RESIZE_DIM)
        predicted_class = predicted_class[:, delta + 1 : RESIZE_DIM - delta - 1]
    elif w0 > h0:
        delta = int(((w0 - h0) / 2) / w0 * RESIZE_DIM)
        predicted_class = predicted_class[delta + 1 : RESIZE_DIM - delta - 1, :]

    resized_mask = cv2.resize(predicted_class, (w0, h0), interpolation=cv2.INTER_NEAREST)
    return resized_mask

# ‚Äî‚Äî‚Äî –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ ‚Äî‚Äî‚Äî
def parse_filename(file_name):
    match = re.match(r"(\d+)-(\d+)", file_name)
    if match:
        return match.group(1), int(match.group(2))
    return file_name, -1

def unzip_and_collect_images(zip_file):
    temp_dir = tempfile.TemporaryDirectory()
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        zip_ref.extractall(temp_dir.name)

    collected = []
    for root, _, files in os.walk(temp_dir.name):
        for file in files:
            if file.lower().endswith((".jpg", ".jpeg", ".png")):
                path = os.path.join(root, file)
                try:
                    image = np.array(Image.open(path).convert("RGB"))
                    collected.append((file, image))
                except:
                    st.warning(f"–§–∞–π–ª {file} –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å")
    return collected

def load_uploaded_images(label_text):
    uploads = st.file_uploader(label_text, accept_multiple_files=True)
    result = []
    for file in uploads or []:
        name = file.name.lower()
        if name.endswith(('.jpg', '.jpeg', '.png')):
            try:
                image = np.array(Image.open(file).convert("RGB"))
                result.append((file.name, image))
            except:
                st.warning(f"–§–∞–π–ª {file.name} –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å")
        elif name.endswith('.zip'):
            result.extend(unzip_and_collect_images(file))
        else:
            st.warning(f"–§–∞–π–ª {file.name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
    return result

# ‚Äî‚Äî‚Äî –ú–∞—Å–∫–∞ –ø–æ–≤–µ—Ä—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî‚Äî‚Äî
def render_mask_overlay(mask: np.ndarray, base_img: np.ndarray, visibility: dict):
    color_scheme = {
        "—Ñ–æ–Ω": np.array([0, 0, 0]),
        "–º–æ—Ö": np.array([42, 125, 209]),
        "–ø–æ—á–≤–∞": np.array([170, 240, 209]),
    }
    painted = base_img.copy()
    for idx, label in enumerate(CLASS_LIST):
        if not visibility.get(label, False):
            continue
        painted[mask == idx] = color_scheme[label]
    return painted

# ‚Äî‚Äî‚Äî –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ‚Äî‚Äî‚Äî
def main_app():
    st.set_page_config(
        page_title="–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –º—Ö–∞",
        page_icon='üåø',
        layout="wide",
        initial_sidebar_state="expanded",
    )
    st.markdown("""<style>h1 a.anchor-link, h2 a.anchor-link, h3 a.anchor-link {
    display: none !important;}</style>""", unsafe_allow_html=True)
    st.title('–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –º—Ö–∞')

    images = load_uploaded_images('–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–∏–ª–∏ .zip)')
    if not images:
        return

    results_data = []
    for name, img in images:
        mask = run_inference(img)
        moss = np.sum(mask == 1)
        soil = np.sum(mask == 2)
        total = moss + soil
        percent = moss / total * 100 if total > 0 else 0
        sample_id, week = parse_filename(name)
        results_data.append({
            "–§–∞–π–ª": name,
            "–û–±—Ä–∞–∑–µ—Ü": sample_id,
            "–ù–µ–¥–µ–ª—è": week,
            "–ü–æ–∫—Ä—ã—Ç–∏–µ –º—Ö–æ–º (%)": round(percent, 2)
        })

    df = pd.DataFrame(results_data).sort_values(by=["–û–±—Ä–∞–∑–µ—Ü", "–ù–µ–¥–µ–ª—è"])
    st.markdown("### üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –º—Ö–æ–º –ø–æ –æ–±—Ä–∞–∑—Ü–∞–º")
    st.dataframe(df)

    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="–ê–Ω–∞–ª–∏–∑ –º—Ö–∞")

    st.sidebar.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É (.xlsx)",
        data=buffer.getvalue(),
        file_name="—Å–≤–æ–¥–Ω–∞—è_—Ç–∞–±–ª–∏—Ü–∞_–º—Ö–∞.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    selected = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ–±—Ä–∞–∑–µ—Ü –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏:", df["–û–±—Ä–∞–∑–µ—Ü"].unique())
    filtered = df[df["–û–±—Ä–∞–∑–µ—Ü"] == selected].sort_values("–ù–µ–¥–µ–ª—è")
    st.line_chart(filtered.set_index("–ù–µ–¥–µ–ª—è")["–ü–æ–∫—Ä—ã—Ç–∏–µ –º—Ö–æ–º (%)"])

    st.sidebar.markdown("### üñåÔ∏è –ü–æ–∫–∞–∑–∞—Ç—å –º–∞—Å–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:")
    default_mask = {
        "–º–æ—Ö": st.sidebar.checkbox("–ú–æ—Ö", value=True),
        "–ø–æ—á–≤–∞": st.sidebar.checkbox("–ü–æ—á–≤–∞", value=False),
        "—Ñ–æ–Ω": st.sidebar.checkbox("–§–æ–Ω", value=False)
    }

    st.sidebar.markdown("### üß≠ –ë—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ—Ö–æ–¥:")
    for name, _ in images:
        encoded = quote(name)
        st.sidebar.markdown(f"<a href='#{encoded}'>{name}</a>", unsafe_allow_html=True)

    for name, image in images:
        encoded = quote(name)
        st.markdown(f"<a name='{encoded}'></a>", unsafe_allow_html=True)
        st.markdown(f"### üñº {name}")
        mask = run_inference(image)

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            st.image(image, use_container_width=True)
        with col2:
            st.subheader("–ú–∞—Å–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")

        st.markdown(f"**–ü–æ–∫–∞–∑–∞—Ç—å –º–∞—Å–∫–∏ –¥–ª—è {name}:**")
        col_mask = st.columns(len(CLASS_LIST))
        toggles = {}
        for i, label in enumerate(CLASS_LIST):
            with col_mask[i]:
                toggles[label] = st.checkbox(label.capitalize(), value=default_mask.get(label, False), key=f"{name}_{label}")

        if all(toggles[k] == default_mask[k] for k in CLASS_LIST):
            toggles = default_mask

        with col2:
            st.image(render_mask_overlay(mask, image, toggles), use_container_width=True)

        moss_area = np.sum(mask == 1)
        soil_area = np.sum(mask == 2)
        total_area = moss_area + soil_area
        percent = moss_area / total_area * 100 if total_area > 0 else 0
        st.markdown(f"**–ü–æ–∫—Ä—ã—Ç–∏–µ –º—Ö–æ–º:** {percent:.2f}%")

if __name__ == '__main__':
    main_app()